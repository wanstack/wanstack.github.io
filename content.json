[{"title":"Neutron SDN 手动实现手册","date":"2017-04-13T15:37:00.000Z","path":"2017/04/13/手工实现SDN/","text":"本文旨在通过自己搭建类似neutron （openvswitch + gre） 实现SDN 的环境，学习了解其工作原理，模拟核心原理，比如：同一租户自定义网络 instance 互通，手动为instance 分配 floating ip 等相关内容。 ###虚拟网络 需要新建3个虚拟网络Net0、Net1和Net2，其在virtual box 中对应配置如下。 Net0: Network name: VirtualBox host-only Ethernet Adapter#2 Purpose: administrator / management network IP block: 10.20.0.0/24 DHCP: disable Linux device: eth0 Net1: Network name: VirtualBox host-only Ethernet Adapter#3 Purpose: public network DHCP: disable IP block: 172.16.0.0/24 Linux device: eth1 Net2： Network name: VirtualBox host-only Ethernet Adapter#4 Purpose: Storage/private network DHCP: disable IP block: 192.168.4.0/24 Linux device: eth2 ###虚拟机 需要新建2个虚拟机VM1和VM2，其对应配置如下。 VM1： Name : network1 vCPU:1 Memory :1G Disk:30G Network:net1,net2,net3 VM2： Name: compute1 vCPU:1 Memory :1G Disk:30G Networks:net1,net2,net3 ###Linux interface设置 network1 eth0:10.20.0.201 (management network) eht1:172.16.0.201 (public/external network) eht2:192.168.4.201 (private network，gre tunning) compute1 eth0:10.20.0.202 (management network) eht1:(disabled) eht2:192.168.4.202 (private network，gre tunning) ##模拟安装网络节点(Network1) 模拟Network 节点相关实现，比如L3、dhcp-agent实现，为了模拟多节点网络情况，这里Network同时也模拟一个计算节点，模拟M2 openvswitch 实现，上面运行instance1。 网络接口配置 1234567891011121314151617181920212223242526vi /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=10.20.0.201 NETMASK=255.255.255.0 vi /etc/sysconfig/network-scripts/ifcfg-eth1 DEVICE=eth1 TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=172.16.0.201 NETMASK=255.255.255.0 vi /etc/sysconfig/network-scripts/ifcfg-eth2 DEVICE=eth2 TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=192.168.4.201 NETMASK=255.255.255.0 重启网络服务 1service network restart 安装需要用到的包 1yum install libvirt openvswitch python-virtinst xauth tigervnc qemu-* -y 移除默认的libvirt 网络，方便清晰分析网络情况 123virsh net-destroy default virsh net-autostart --disable default virsh net-undefine default 设置允许ipforwarding 1234vi /etc/sysctl.conf net.ipv4.ip_forward=1 net.ipv4.conf.all.rp_filter=0 net.ipv4.conf.default.rp_filter=0 立即生效 1sysctl -p 启动openvswitch 12service openvswitch startchkconfig openvswitch on 创建一个linux bridge 12brctl addbr qbr01ip link set qbr01 up 创建一个instance，并连接到qbr01 Bridge，网络接口部分配置如下 1234567 &lt;interface type=&apos;bridge&apos;&gt; &lt;source bridge=&apos;qbr01&apos;/&gt; &lt;target dev=&apos;tap01&apos;/&gt; &lt;model type=&apos;virtio&apos;/&gt; &lt;driver name=&apos;qemu&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x03&apos; function=&apos;0x0&apos;/&gt;&lt;/interface&gt; 可以参考附件./gre/instance1.xml创建 1234567 cp ~/gre/ /var/tmp/cd /var/tmp/gremv cirros-0.3.0-x86_64-disk.img instance1.imgvirsh define instance1.xmlvirsh start instance1virsh vncdisplay instance1vncviewer :0 启动console 以后,登录添加ip 地址 192.168.1.11 12 ip addr add 192.168.1.11/24 dev eth0route add default gw 192.168.1.1 创建一个内部bridge br-int， 模拟 OpenStack integrated bridge 12 ovs-vsctl add-br br-intovs-vsctl add-port br-int gre0 -- set interface gre0 type=gre options:remote_ip=192.168.4.202 创建一个veth peer，连接Linux Bridge ‘qbr01’ 和 OpenvSwich Bridge ‘br-ini’ 123456 ip link add qvo01 type veth peer name qvb01brctl addif qbr01 qvb01ovs-vsctl add-port br-int qvo01ovs-vsctl set port qvo01 tag=100ip link set qvb01 upip link set qvo01 up 查看现在network1上的 br-int 1ovs-vsctl show ##模拟安装计算节点(compute1) ##网络接口配置 1234567891011121314151617181920212223242526 vi /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0TYPE=EthernetONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=10.20.0.202NETMASK=255.255.255.0vi /etc/sysconfig/network-scripts/ifcfg-eth1DEVICE=eth1TYPE=EthernetONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=172.16.0.202NETMASK=255.255.255.0vi /etc/sysconfig/network-scripts/ifcfg-eth2DEVICE=eth2TYPE=EthernetONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=staticIPADDR=192.168.4.202NETMASK=255.255.255.0 重启网络服务 1service network restart 安装需要用到的包 1yum install libvirt openvswitch python-virtinst xauth tigervnc qemu-* 移除libvirt 默认的网络 123virsh net-destroy defaultvirsh net-autostart --disableu defaultvirsh net-undefine default 设置允许ipforwarding 1234vi /etc/sysctl.conf net.ipv4.ip_forward=1net.ipv4.conf.all.rp_filter=0net.ipv4.conf.default.rp_filter=0 立即生效 1sysctl -p 启动openvswitch 12service openvswitch startchkconfig openvswitch on 创建一个linux bridge 12brctl addbr qbr02ip link set qbr02 up 创建一个vm，并连接到qbr02 1234567&lt;interface type=&apos;bridge&apos;&gt; &lt;source bridge=&apos;qbr02&apos;/&gt; &lt;target dev=&apos;tap02&apos;/&gt; &lt;model type=&apos;virtio&apos;/&gt; &lt;driver name=&apos;qemu&apos;/&gt; &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x03&apos; function=&apos;0x0&apos;/&gt;&lt;/interface&gt; 上gre目录到compute1 节点，可以参考附件./gre/instance2.xml创建 1234567cp ~/gre/ /var/tmp/cd /var/tmp/gremv cirros-0.3.0-x86_64-disk.img instance2.imgvirsh define instance2.xmlvirsh start instance2virsh vncdisplay instance2vncviewer :0 启动console 以后,登录添加ip得知 192.168.1.12 12ip addr add 192.168.1.12/24 dev eth0route add default gw 192.168.1.1 创建一个内部bridge br-int， 模拟 OpenStack integrated bridge 12ovs-vsctl add-br br-intovs-vsctl add-port br-int gre0 -- set interface gre0 type=gre options:remote_ip=192.168.4.201 创建一个veth peer，连接Linux Bridge ‘qbr02’ 和 OpenvSwich Bridge ‘br-ini’ 123456ip link add qvo02 type veth peer name qvb02brctl addif qbr02 qvb02ovs-vsctl add-port br-int qvo02ovs-vsctl set port qvo02 tag=100ip link set qvb02 upip link set qvo02 up 查看现在network1 上的 br-int 1ovs-vsctl show 检查是否能连通instance1，在instance2的控制台 1ping 192.168.1.11 ##通过 Network Namespace 实现租户私有网络互访 添加一个namespace，dhcp01用于隔离租户网络。 1ip netns add dhcp01 为私有网络192.168.1.0/24 ，在命名空间dhcp01 中 创建dhcp 服务 12345ovs-vsctl add-port br-int tapdhcp01 -- set interface tapdhcp01 type=internalovs-vsctl set port tapdhcp01 tag=100ip link set tapdhcp01 netns dhcp01ip netns exec dhcp01 ip addr add 192.168.1.2/24 dev tapdhcp01ip netns exec dhcp01 ip link set tapdhcp01 up 检查网络是否连通，在namespace 访问instance1 和 instance2 12ip netns exec dhcp01 ping 192.168.1.12ip netns exec dhcp01 ping 192.168.1.11 ##通过 Network Namespace 和Iptables 实现L3 router 1ovs-vsctl add-br br-ex 重新配置eth1 和 br-ex 123456789101112131415161718192021222324252627282930313233343536vi /etc/sysconfig/network-scripts/ifcfg-eth1 DEVICE=eth1 ONBOOT=yes BOOTPROTO=none PROMISC=yes MTU=1546 ################################### DEVICE=ens160TYPE=OVSPortDEVICETYPE=ovsOVS_BRIDGE=br-exONBOOT=yes #################################### vi /etc/sysconfig/network-scripts/ifcfg-br-ex DEVICE=br-ex TYPE=Bridge ONBOOT=yes BOOTPROTO=none IPADDR0=172.16.0.201 PREFIX0=24 ####################################### DEVICE=br-exONBOOT=yesDEVICETYPE=ovsTYPE=OVSBridgeBOOTPROTO=staticIPADDR=192.168.2.134NETMASK=255.255.255.0GATEWAY=192.168.2.1DNS1=218.2.2.2 ###################################### 重启启动网络服务 1ovs-vsctl add-port br-ex eth1 &amp;&amp; service network restart 检查网络，配置后是否连通 1ping 172.16.0.201 添加一个namespace，router01 用于路由和floating ip 分配 1ip netns add router01 在br-int添加一个接口，作为私有网络192.168.1.0/24的网关 123456789ovs-vsctl add-port br-int qr01 -- set interface qr01 type=internalovs-vsctl set port qr01 tag=100 ip link set qr01 netns router01 ip netns exec router01 ip addr add 192.168.1.1/24 dev qr01 ip netns exec router01 ip link set qr01 up ip netns exec router01 ip link set lo up 在br-ex中添加一个接口，用于私网192.168.1.0/24设置下一跳地址 12345ovs-vsctl add-port br-ex qg01 -- set interface qg01 type=internal ip link set qg01 netns router01 ip netns exec router01 ip addr add 172.16.0.100/24 dev qg01 ip netns exec router01 ip link set qg01 up ip netns exec router01 ip link set lo up 模拟分配floating ip 访问instance1为instance1 192.168.1.11 分配floating ip，172.16.0.101 123456ip netns exec router01 ip addr add 172.16.0.101/32 dev qg01 ip netns exec router01 iptables -t nat -A OUTPUT -d 172.16.0.101/32 -j DNAT --to-destination 192.168.1.11 ip netns exec router01 iptables -t nat -A PREROUTING -d 172.16.0.101/32 -j DNAT --to-destination 192.168.1.11 ip netns exec router01 iptables -t nat -A POSTROUTING -s 192.168.1.11/32 -j SNAT --to-source 172.16.0.101 ip netns exec router01 iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -j SNAT --to-source 172.16.0.100 测试floating ip 1ping 172.16.0.101 如果需要清除nat chain 1iptables -t nat -F 1234567891011ip netns exec router01 iptables -t nat -A OUTPUT -d 192.168.2.102/32 -j DNAT --to-destination 192.168.10.11ip netns exec router01 iptables -t nat -A PREROUTING -d 192.168.2.102/32 -j DNAT --to-destination 192.168.10.11ip netns exec router01 iptables -t nat -A POSTROUTING -s 192.168.10.11/32 -j SNAT --to-source 192.168.2.102ip netns exec router01 ip addr add 192.168.2.103/32 dev qg01ip netns exec router01 iptables -t nat -A OUTPUT -d 192.168.2.103/32 -j DNAT --to-destination 192.168.10.11ip netns exec router01 iptables -t nat -A PREROUTING -d 192.168.2.103/32 -j DNAT --to-destination 192.168.10.11ip netns exec router01 iptables -t nat -A POSTROUTING -s 192.168.10.11/32 -j SNAT --to-source 192.168.2.103ip netns exec router01 route add default gw 192.168.2.1ip netns exec router01 route -n","tags":[{"name":"Network","slug":"Network","permalink":"http://yoursite.com/tags/Network/"}]},{"title":"packstack 安装配置openstack mitaka","date":"2017-03-30T01:20:00.000Z","path":"2017/03/30/packstack install openstack-mitaka/","text":"1、修改主机名 12345678hostnamectl set-hostname controllerhostname controllerhostnamectl set-hostname compute01hostname compute01hostnamectl set-hostname compute02hostname compute02 1234567cat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.12.50 controller192.168.12.51 compute01192.168.12.52 compute02 2、安装基础yum源 123456yum install ntpdate -yecho &quot;*/5 * * * * /usr/sbin/ntpdate 192.168.2.161 &gt;/dev/null 2&gt;&amp;1&quot; &gt;&gt; /var/spool/cron/root/usr/sbin/ntpdate 192.168.2.161yum install wget -yrm -rf /etc/yum.repos.d/*wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 3、安装配置openstack源 123456789yum install -y centos-release-openstack-mitakavim CentOS-OpenStack-mitaka.repo [centos-openstack-mitaka]name=CentOS-7 - OpenStack mitakabaseurl=http://mirrors.aliyun.com/centos/7/cloud/$basearch/openstack-mitaka/gpgcheck=1enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-Cloud 4、安装配置openstack 1yum update -y 控制节点执行: CONFIG_PROVISION_DEMO=n 123yum install -y openstack-packstackpackstack --gen-answer-file=openstack.txt 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317[root@controller ~]# cat openstack.txt | egrep -v &quot;^$|^#&quot;[general]CONFIG_SSH_KEY=/root/.ssh/id_rsa.pubCONFIG_DEFAULT_PASSWORD=CONFIG_SERVICE_WORKERS=%&#123;::processorcount&#125;CONFIG_MARIADB_INSTALL=yCONFIG_GLANCE_INSTALL=yCONFIG_CINDER_INSTALL=yCONFIG_MANILA_INSTALL=nCONFIG_NOVA_INSTALL=yCONFIG_NEUTRON_INSTALL=yCONFIG_HORIZON_INSTALL=yCONFIG_SWIFT_INSTALL=yCONFIG_CEILOMETER_INSTALL=yCONFIG_AODH_INSTALL=yCONFIG_GNOCCHI_INSTALL=yCONFIG_SAHARA_INSTALL=nCONFIG_HEAT_INSTALL=nCONFIG_TROVE_INSTALL=nCONFIG_IRONIC_INSTALL=nCONFIG_CLIENT_INSTALL=yCONFIG_NTP_SERVERS=CONFIG_NAGIOS_INSTALL=yEXCLUDE_SERVERS=CONFIG_DEBUG_MODE=nCONFIG_CONTROLLER_HOST=192.168.12.50CONFIG_COMPUTE_HOSTS=192.168.12.51,192.168.12.52CONFIG_NETWORK_HOSTS=192.168.12.50CONFIG_VMWARE_BACKEND=nCONFIG_UNSUPPORTED=nCONFIG_USE_SUBNETS=nCONFIG_VCENTER_HOST=CONFIG_VCENTER_USER=CONFIG_VCENTER_PASSWORD=CONFIG_VCENTER_CLUSTER_NAMES=CONFIG_STORAGE_HOST=192.168.12.50CONFIG_SAHARA_HOST=192.168.12.50CONFIG_USE_EPEL=nCONFIG_REPO=CONFIG_ENABLE_RDO_TESTING=nCONFIG_RH_USER=CONFIG_SATELLITE_URL=CONFIG_RH_SAT6_SERVER=CONFIG_RH_PW=CONFIG_RH_OPTIONAL=yCONFIG_RH_PROXY=CONFIG_RH_SAT6_ORG=CONFIG_RH_SAT6_KEY=CONFIG_RH_PROXY_PORT=CONFIG_RH_PROXY_USER=CONFIG_RH_PROXY_PW=CONFIG_SATELLITE_USER=CONFIG_SATELLITE_PW=CONFIG_SATELLITE_AKEY=CONFIG_SATELLITE_CACERT=CONFIG_SATELLITE_PROFILE=CONFIG_SATELLITE_FLAGS=CONFIG_SATELLITE_PROXY=CONFIG_SATELLITE_PROXY_USER=CONFIG_SATELLITE_PROXY_PW=CONFIG_SSL_CACERT_FILE=/etc/pki/tls/certs/selfcert.crtCONFIG_SSL_CACERT_KEY_FILE=/etc/pki/tls/private/selfkey.keyCONFIG_SSL_CERT_DIR=~/packstackca/CONFIG_SSL_CACERT_SELFSIGN=yCONFIG_SELFSIGN_CACERT_SUBJECT_C=--CONFIG_SELFSIGN_CACERT_SUBJECT_ST=StateCONFIG_SELFSIGN_CACERT_SUBJECT_L=CityCONFIG_SELFSIGN_CACERT_SUBJECT_O=openstackCONFIG_SELFSIGN_CACERT_SUBJECT_OU=packstackCONFIG_SELFSIGN_CACERT_SUBJECT_CN=controllerCONFIG_SELFSIGN_CACERT_SUBJECT_MAIL=admin@controllerCONFIG_AMQP_BACKEND=rabbitmqCONFIG_AMQP_HOST=192.168.12.50CONFIG_AMQP_ENABLE_SSL=nCONFIG_AMQP_ENABLE_AUTH=nCONFIG_AMQP_NSS_CERTDB_PW=PW_PLACEHOLDERCONFIG_AMQP_AUTH_USER=amqp_userCONFIG_AMQP_AUTH_PASSWORD=PW_PLACEHOLDERCONFIG_MARIADB_HOST=192.168.12.50CONFIG_MARIADB_USER=rootCONFIG_MARIADB_PW=openstackCONFIG_KEYSTONE_DB_PW=38cddfa9ce6149c9CONFIG_KEYSTONE_DB_PURGE_ENABLE=TrueCONFIG_KEYSTONE_REGION=RegionOneCONFIG_KEYSTONE_ADMIN_TOKEN=e462f66d03974d8fa410cf76aae40da9CONFIG_KEYSTONE_ADMIN_EMAIL=root@localhostCONFIG_KEYSTONE_ADMIN_USERNAME=adminCONFIG_KEYSTONE_ADMIN_PW=adminCONFIG_KEYSTONE_DEMO_PW=demoCONFIG_KEYSTONE_API_VERSION=v2.0CONFIG_KEYSTONE_TOKEN_FORMAT=UUIDCONFIG_KEYSTONE_SERVICE_NAME=httpdCONFIG_KEYSTONE_IDENTITY_BACKEND=sqlCONFIG_KEYSTONE_LDAP_URL=ldap://192.168.12.50CONFIG_KEYSTONE_LDAP_USER_DN=CONFIG_KEYSTONE_LDAP_USER_PASSWORD=CONFIG_KEYSTONE_LDAP_SUFFIX=CONFIG_KEYSTONE_LDAP_QUERY_SCOPE=oneCONFIG_KEYSTONE_LDAP_PAGE_SIZE=-1CONFIG_KEYSTONE_LDAP_USER_SUBTREE=CONFIG_KEYSTONE_LDAP_USER_FILTER=CONFIG_KEYSTONE_LDAP_USER_OBJECTCLASS=CONFIG_KEYSTONE_LDAP_USER_ID_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_USER_NAME_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_USER_MAIL_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_USER_ENABLED_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_USER_ENABLED_MASK=-1CONFIG_KEYSTONE_LDAP_USER_ENABLED_DEFAULT=TRUECONFIG_KEYSTONE_LDAP_USER_ENABLED_INVERT=nCONFIG_KEYSTONE_LDAP_USER_ATTRIBUTE_IGNORE=CONFIG_KEYSTONE_LDAP_USER_DEFAULT_PROJECT_ID_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_USER_ALLOW_CREATE=nCONFIG_KEYSTONE_LDAP_USER_ALLOW_UPDATE=nCONFIG_KEYSTONE_LDAP_USER_ALLOW_DELETE=nCONFIG_KEYSTONE_LDAP_USER_PASS_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_USER_ENABLED_EMULATION_DN=CONFIG_KEYSTONE_LDAP_USER_ADDITIONAL_ATTRIBUTE_MAPPING=CONFIG_KEYSTONE_LDAP_GROUP_SUBTREE=CONFIG_KEYSTONE_LDAP_GROUP_FILTER=CONFIG_KEYSTONE_LDAP_GROUP_OBJECTCLASS=CONFIG_KEYSTONE_LDAP_GROUP_ID_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_GROUP_NAME_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_GROUP_MEMBER_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_GROUP_DESC_ATTRIBUTE=CONFIG_KEYSTONE_LDAP_GROUP_ATTRIBUTE_IGNORE=CONFIG_KEYSTONE_LDAP_GROUP_ALLOW_CREATE=nCONFIG_KEYSTONE_LDAP_GROUP_ALLOW_UPDATE=nCONFIG_KEYSTONE_LDAP_GROUP_ALLOW_DELETE=nCONFIG_KEYSTONE_LDAP_GROUP_ADDITIONAL_ATTRIBUTE_MAPPING=CONFIG_KEYSTONE_LDAP_USE_TLS=nCONFIG_KEYSTONE_LDAP_TLS_CACERTDIR=CONFIG_KEYSTONE_LDAP_TLS_CACERTFILE=CONFIG_KEYSTONE_LDAP_TLS_REQ_CERT=demandCONFIG_GLANCE_DB_PW=b5b27691c2a14788CONFIG_GLANCE_KS_PW=3ed7ad2ece9146a9CONFIG_GLANCE_BACKEND=fileCONFIG_CINDER_DB_PW=dadf81afd3be45ccCONFIG_CINDER_DB_PURGE_ENABLE=TrueCONFIG_CINDER_KS_PW=68c0f33d48664240CONFIG_CINDER_BACKEND=lvmCONFIG_CINDER_VOLUMES_CREATE=yCONFIG_CINDER_VOLUMES_SIZE=20GCONFIG_CINDER_GLUSTER_MOUNTS=CONFIG_CINDER_NFS_MOUNTS=CONFIG_CINDER_NETAPP_LOGIN=CONFIG_CINDER_NETAPP_PASSWORD=CONFIG_CINDER_NETAPP_HOSTNAME=CONFIG_CINDER_NETAPP_SERVER_PORT=80CONFIG_CINDER_NETAPP_STORAGE_FAMILY=ontap_clusterCONFIG_CINDER_NETAPP_TRANSPORT_TYPE=httpCONFIG_CINDER_NETAPP_STORAGE_PROTOCOL=nfsCONFIG_CINDER_NETAPP_SIZE_MULTIPLIER=1.0CONFIG_CINDER_NETAPP_EXPIRY_THRES_MINUTES=720CONFIG_CINDER_NETAPP_THRES_AVL_SIZE_PERC_START=20CONFIG_CINDER_NETAPP_THRES_AVL_SIZE_PERC_STOP=60CONFIG_CINDER_NETAPP_NFS_SHARES=CONFIG_CINDER_NETAPP_NFS_SHARES_CONFIG=/etc/cinder/shares.confCONFIG_CINDER_NETAPP_VOLUME_LIST=CONFIG_CINDER_NETAPP_VFILER=CONFIG_CINDER_NETAPP_PARTNER_BACKEND_NAME=CONFIG_CINDER_NETAPP_VSERVER=CONFIG_CINDER_NETAPP_CONTROLLER_IPS=CONFIG_CINDER_NETAPP_SA_PASSWORD=CONFIG_CINDER_NETAPP_ESERIES_HOST_TYPE=linux_dm_mpCONFIG_CINDER_NETAPP_WEBSERVICE_PATH=/devmgr/v2CONFIG_CINDER_NETAPP_STORAGE_POOLS=CONFIG_IRONIC_DB_PW=PW_PLACEHOLDERCONFIG_IRONIC_KS_PW=PW_PLACEHOLDERCONFIG_NOVA_DB_PURGE_ENABLE=TrueCONFIG_NOVA_DB_PW=588239b4fe244aebCONFIG_NOVA_KS_PW=3f355b76a92d41f1CONFIG_NOVA_SCHED_CPU_ALLOC_RATIO=16.0CONFIG_NOVA_SCHED_RAM_ALLOC_RATIO=1.5CONFIG_NOVA_COMPUTE_MIGRATE_PROTOCOL=tcpCONFIG_NOVA_COMPUTE_MANAGER=nova.compute.manager.ComputeManagerCONFIG_VNC_SSL_CERT=CONFIG_VNC_SSL_KEY=CONFIG_NOVA_PCI_ALIAS=CONFIG_NOVA_PCI_PASSTHROUGH_WHITELIST=CONFIG_NOVA_LIBVIRT_VIRT_TYPE=%&#123;::default_hypervisor&#125;CONFIG_NOVA_COMPUTE_PRIVIF=CONFIG_NOVA_NETWORK_MANAGER=nova.network.manager.FlatDHCPManagerCONFIG_NOVA_NETWORK_PUBIF=eth0CONFIG_NOVA_NETWORK_PRIVIF=CONFIG_NOVA_NETWORK_FIXEDRANGE=192.168.32.0/22CONFIG_NOVA_NETWORK_FLOATRANGE=10.3.4.0/22CONFIG_NOVA_NETWORK_AUTOASSIGNFLOATINGIP=nCONFIG_NOVA_NETWORK_VLAN_START=100CONFIG_NOVA_NETWORK_NUMBER=1CONFIG_NOVA_NETWORK_SIZE=255CONFIG_NEUTRON_KS_PW=e6c0896ef2fa412cCONFIG_NEUTRON_DB_PW=1202d0c54fdb4f5dCONFIG_NEUTRON_L3_EXT_BRIDGE=br-exCONFIG_NEUTRON_METADATA_PW=fd7e182acbc842e3CONFIG_LBAAS_INSTALL=nCONFIG_NEUTRON_METERING_AGENT_INSTALL=yCONFIG_NEUTRON_FWAAS=nCONFIG_NEUTRON_VPNAAS=nCONFIG_NEUTRON_ML2_TYPE_DRIVERS=vxlanCONFIG_NEUTRON_ML2_TENANT_NETWORK_TYPES=vxlanCONFIG_NEUTRON_ML2_MECHANISM_DRIVERS=openvswitchCONFIG_NEUTRON_ML2_FLAT_NETWORKS=*CONFIG_NEUTRON_ML2_VLAN_RANGES=CONFIG_NEUTRON_ML2_TUNNEL_ID_RANGES=CONFIG_NEUTRON_ML2_VXLAN_GROUP=CONFIG_NEUTRON_ML2_VNI_RANGES=10:100CONFIG_NEUTRON_L2_AGENT=openvswitchCONFIG_NEUTRON_ML2_SUPPORTED_PCI_VENDOR_DEVS=[&apos;15b3:1004&apos;, &apos;8086:10ca&apos;]CONFIG_NEUTRON_ML2_SRIOV_AGENT_REQUIRED=nCONFIG_NEUTRON_ML2_SRIOV_INTERFACE_MAPPINGS=CONFIG_NEUTRON_LB_INTERFACE_MAPPINGS=CONFIG_NEUTRON_OVS_BRIDGE_MAPPINGS=CONFIG_NEUTRON_OVS_BRIDGE_IFACES=CONFIG_NEUTRON_OVS_BRIDGES_COMPUTE=CONFIG_NEUTRON_OVS_TUNNEL_IF=CONFIG_NEUTRON_OVS_TUNNEL_SUBNETS=CONFIG_NEUTRON_OVS_VXLAN_UDP_PORT=4789CONFIG_MANILA_DB_PW=PW_PLACEHOLDERCONFIG_MANILA_KS_PW=PW_PLACEHOLDERCONFIG_MANILA_BACKEND=genericCONFIG_MANILA_NETAPP_DRV_HANDLES_SHARE_SERVERS=falseCONFIG_MANILA_NETAPP_TRANSPORT_TYPE=httpsCONFIG_MANILA_NETAPP_LOGIN=adminCONFIG_MANILA_NETAPP_PASSWORD=CONFIG_MANILA_NETAPP_SERVER_HOSTNAME=CONFIG_MANILA_NETAPP_STORAGE_FAMILY=ontap_clusterCONFIG_MANILA_NETAPP_SERVER_PORT=443CONFIG_MANILA_NETAPP_AGGREGATE_NAME_SEARCH_PATTERN=(.*)CONFIG_MANILA_NETAPP_ROOT_VOLUME_AGGREGATE=CONFIG_MANILA_NETAPP_ROOT_VOLUME_NAME=rootCONFIG_MANILA_NETAPP_VSERVER=CONFIG_MANILA_GENERIC_DRV_HANDLES_SHARE_SERVERS=trueCONFIG_MANILA_GENERIC_VOLUME_NAME_TEMPLATE=manila-share-%sCONFIG_MANILA_GENERIC_SHARE_MOUNT_PATH=/sharesCONFIG_MANILA_SERVICE_IMAGE_LOCATION=https://www.dropbox.com/s/vi5oeh10q1qkckh/ubuntu_1204_nfs_cifs.qcow2CONFIG_MANILA_SERVICE_INSTANCE_USER=ubuntuCONFIG_MANILA_SERVICE_INSTANCE_PASSWORD=ubuntuCONFIG_MANILA_NETWORK_TYPE=neutronCONFIG_MANILA_NETWORK_STANDALONE_GATEWAY=CONFIG_MANILA_NETWORK_STANDALONE_NETMASK=CONFIG_MANILA_NETWORK_STANDALONE_SEG_ID=CONFIG_MANILA_NETWORK_STANDALONE_IP_RANGE=CONFIG_MANILA_NETWORK_STANDALONE_IP_VERSION=4CONFIG_MANILA_GLUSTERFS_SERVERS=CONFIG_MANILA_GLUSTERFS_NATIVE_PATH_TO_PRIVATE_KEY=CONFIG_MANILA_GLUSTERFS_VOLUME_PATTERN=CONFIG_MANILA_GLUSTERFS_TARGET=CONFIG_MANILA_GLUSTERFS_MOUNT_POINT_BASE=CONFIG_MANILA_GLUSTERFS_NFS_SERVER_TYPE=glusterCONFIG_MANILA_GLUSTERFS_PATH_TO_PRIVATE_KEY=CONFIG_MANILA_GLUSTERFS_GANESHA_SERVER_IP=CONFIG_HORIZON_SSL=nCONFIG_HORIZON_SECRET_KEY=82c2cbbf5e744a4785e2d0ddd3ec9b80CONFIG_HORIZON_SSL_CERT=CONFIG_HORIZON_SSL_KEY=CONFIG_HORIZON_SSL_CACERT=CONFIG_SWIFT_KS_PW=d7b6a1ec2c8f4334CONFIG_SWIFT_STORAGES=CONFIG_SWIFT_STORAGE_ZONES=1CONFIG_SWIFT_STORAGE_REPLICAS=1CONFIG_SWIFT_STORAGE_FSTYPE=ext4CONFIG_SWIFT_HASH=67485c805b524830CONFIG_SWIFT_STORAGE_SIZE=2GCONFIG_HEAT_DB_PW=PW_PLACEHOLDERCONFIG_HEAT_AUTH_ENC_KEY=ac8680aafaca4fa9CONFIG_HEAT_KS_PW=PW_PLACEHOLDERCONFIG_HEAT_CLOUDWATCH_INSTALL=nCONFIG_HEAT_CFN_INSTALL=nCONFIG_HEAT_DOMAIN=heatCONFIG_HEAT_DOMAIN_ADMIN=heat_adminCONFIG_HEAT_DOMAIN_PASSWORD=PW_PLACEHOLDERCONFIG_PROVISION_DEMO=nCONFIG_PROVISION_TEMPEST=nCONFIG_PROVISION_DEMO_FLOATRANGE=172.24.4.224/28CONFIG_PROVISION_IMAGE_NAME=cirrosCONFIG_PROVISION_IMAGE_URL=http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.imgCONFIG_PROVISION_IMAGE_FORMAT=qcow2CONFIG_PROVISION_IMAGE_SSH_USER=cirrosCONFIG_PROVISION_UEC_IMAGE_NAME=cirros-uecCONFIG_PROVISION_UEC_IMAGE_KERNEL_URL=http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-kernelCONFIG_PROVISION_UEC_IMAGE_RAMDISK_URL=http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-initramfsCONFIG_PROVISION_UEC_IMAGE_DISK_URL=http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.imgCONFIG_TEMPEST_HOST=CONFIG_PROVISION_TEMPEST_USER=CONFIG_PROVISION_TEMPEST_USER_PW=PW_PLACEHOLDERCONFIG_PROVISION_TEMPEST_FLOATRANGE=172.24.4.224/28CONFIG_PROVISION_TEMPEST_REPO_URI=https://github.com/openstack/tempest.gitCONFIG_PROVISION_TEMPEST_REPO_REVISION=masterCONFIG_RUN_TEMPEST=nCONFIG_RUN_TEMPEST_TESTS=smokeCONFIG_PROVISION_OVS_BRIDGE=yCONFIG_GNOCCHI_DB_PW=9e46b3492cd441aeCONFIG_GNOCCHI_KS_PW=553369ab22294506CONFIG_CEILOMETER_SECRET=7d41192be1264a47CONFIG_CEILOMETER_KS_PW=2b56ad68aab341a0CONFIG_CEILOMETER_SERVICE_NAME=httpdCONFIG_CEILOMETER_COORDINATION_BACKEND=redisCONFIG_CEILOMETER_METERING_BACKEND=databaseCONFIG_MONGODB_HOST=192.168.12.50CONFIG_REDIS_MASTER_HOST=192.168.12.50CONFIG_REDIS_PORT=6379CONFIG_REDIS_HA=nCONFIG_REDIS_SLAVE_HOSTS=CONFIG_REDIS_SENTINEL_HOSTS=CONFIG_REDIS_SENTINEL_CONTACT_HOST=CONFIG_REDIS_SENTINEL_PORT=26379CONFIG_REDIS_SENTINEL_QUORUM=2CONFIG_REDIS_MASTER_NAME=mymasterCONFIG_AODH_KS_PW=d6881f5b3b0e4ce2CONFIG_TROVE_DB_PW=PW_PLACEHOLDERCONFIG_TROVE_KS_PW=PW_PLACEHOLDERCONFIG_TROVE_NOVA_USER=troveCONFIG_TROVE_NOVA_TENANT=servicesCONFIG_TROVE_NOVA_PW=PW_PLACEHOLDERCONFIG_SAHARA_DB_PW=PW_PLACEHOLDERCONFIG_SAHARA_KS_PW=PW_PLACEHOLDERCONFIG_NAGIOS_PW=383e86a1cd4348b5 5、安装 1packstack --answer-file=openstack.txt 6、安装后的修改 1234vim /etc/neutron/plugins/ml2/ml2_conf.ini 修改控制节点网络配置:[ml2_type_flat]flat_networks = * 1234567891011121314151617修改控制节点网卡配置:[root@controller network-scripts(keystone_admin)]# cat ifcfg-ens160 DEVICE=ens160TYPE=OVSPortDEVICETYPE=ovsOVS_BRIDGE=br-exONBOOT=yes[root@controller network-scripts(keystone_admin)]# cat ifcfg-br-ex DEVICE=br-exONBOOT=yesDEVICETYPE=ovsTYPE=OVSBridgeBOOTPROTO=staticIPADDR=192.168.12.50NETMASK=255.255.255.0GATEWAY=192.168.12.1DNS1=218.2.2.2 #####################为2个计算节点挂载共享存储，本次是nfs 12345678910111213141516171819202122232425262728293031323334353637383940找一个硬盘分区后，此次是sdc1挂载到/opt/nova/instances上[root@cinder ~]# cat /etc/fstab /dev/mapper/centos-root / xfs defaults 0 0UUID=06e34a87-b0fc-40e5-aae2-fa4d136543fc /boot xfs defaults 0 0/dev/mapper/centos-swap swap swap defaults 0 0/dev/sdc1 /opt/nova/instances xfs defaults 0 0格式化/dev/sdc1:mkfs.xfs /dev/sdb1修改过/etc/fstab后mount -a 即可生效yum -y install nfs-utils rpcbind -yvim /etc/exports/opt/nova/instances 192.168.12.0/24(rw,no_root_squash,no_all_squash,sync)exportfs -rsystemctl enable rpcbind.servicesystemctl start rpcbind.servicesystemctl enable nfs-server.service systemctl start nfs-server.service 2、2个nova节点查看showmount -e 192.168.12.50mount -t nfs 192.168.12.50:/opt/nova/instances /var/lib/nova/instances/mount -a2个nova节点：chown -R nova.nova /var/lib/nova","tags":[{"name":"Openstack","slug":"Openstack","permalink":"http://yoursite.com/tags/Openstack/"}]},{"title":"devstack mitaka 安装配置","date":"2017-03-29T15:37:00.000Z","path":"2017/03/29/devstack/","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551、操作系统ubuntu 14.04 2、安装方式 devstack 3、安装版本 openstack mitaka版本4、安装devstack 步骤1) 目前国内已经提供了完整的OpenStack的github的mirrorhttp://git.trystack.cn2) 另外devstack还会下载image，下载的过程也是非常缓慢。trystack也提供大家常用的image下载。http://images.trystack.cn3) 设置源sudo vim /etc/apt/sources.listdeb http://cn.archive.ubuntu.com/ubuntu/ trusty main restricted universe multiversedeb http://cn.archive.ubuntu.com/ubuntu/ trusty-security main restricted universe multiversedeb http://cn.archive.ubuntu.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://cn.archive.ubuntu.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://cn.archive.ubuntu.com/ubuntu/ trusty-backports main restricted universe multiversesudo apt-get updatesudo ntpdate 192.168.2.161sudo apt-get install git -ysudo git clone http://git.trystack.cn/openstack-dev/devstack.git -b stable/mitaka# 目前Devstack脚本已经不支持直接使用root身份运行，你需要创建stack用户运行cd devstack/tools/sudo ./create-stack-user.shsudo passwd stack# 修改devstack目录权限,让stack用户可以运行sudo chown -R stack:stack devstacksudo chmod 777 /dev/pts/0su stackcd devstackvim local.confstack@ubuntu:/home/wanstack/devstack$ cat local.conf [[local|localrc]]# use TryStack git mirrorGIT_BASE=http://git.trystack.cnNOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.gitSPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git#OFFLINE=TrueRECLONE=False# Define images to be automatically downloaded during the DevStack built process.DOWNLOAD_DEFAULT_IMAGES=FalseIMAGE_URLS=&quot;http://images.trystack.cn/cirros/cirros-0.3.4-x86_64-disk.img&quot;HOST_IP=192.168.12.10# CredentialsDATABASE_PASSWORD=openstackADMIN_PASSWORD=openstackSERVICE_PASSWORD=openstackSERVICE_TOKEN=openstackRABBIT_PASSWORD=openstackHORIZON_BRANCH=stable/mitakaKEYSTONE_BRANCH=stable/mitakaNOVA_BRANCH=stable/mitakaNEUTRON_BRANCH=stable/mitakaGLANCE_BRANCH=stable/mitakaCINDER_BRANCH=stable/mitakaCEILOMETER_BRANCH=stable/mitakaAODH_BRANCH=stable/mitakaenable_plugin ceilometer https://git.openstack.org/openstack/ceilometer stable/mitakaenable_plugin aodh https://git.openstack.org/openstack/aodh stable/mitaka#keystoneKEYSTONE_TOKEN_FORMAT=UUID##HeatHEAT_BRANCH=stable/mitakaenable_service h-eng h-api h-api-cfn h-api-cw## SwiftSWIFT_BRANCH=stable/mitakaENABLED_SERVICES+=,s-proxy,s-object,s-container,s-accountSWIFT_REPLICAS=1SWIFT_HASH=011688b44136573e209e# Enabling Neutron (network) Servicedisable_service n-netenable_service q-svcenable_service q-agtenable_service q-dhcpenable_service q-l3enable_service q-metaenable_service q-meteringenable_service neutron## Neutron optionsQ_USE_SECGROUP=TrueFLOATING_RANGE=&quot;192.168.12.0/24&quot;FIXED_RANGE=&quot;10.0.0.0/24&quot;Q_FLOATING_ALLOCATION_POOL=start=192.168.12.110,end=192.168.12.120PUBLIC_NETWORK_GATEWAY=&quot;192.168.12.1&quot;Q_L3_ENABLED=TruePUBLIC_INTERFACE=eth0Q_USE_PROVIDERNET_FOR_PUBLIC=TrueOVS_PHYSICAL_BRIDGE=br-exPUBLIC_BRIDGE=br-exOVS_BRIDGE_MAPPINGS=public:br-ex# #VLAN configuration.Q_PLUGIN=ml2ENABLE_TENANT_VLANS=True# LoggingLOGFILE=/opt/stack/logs/stack.sh.logVERBOSE=TrueLOG_COLOR=TrueSCREEN_LOGDIR=/opt/stack/logs报错:File &quot;/usr/local/lib/python2.7/dist-packages/pip/_vendor/requests/packages/urllib3/response.py&quot;, line 246, in _error_catcher2017-03-21 07:54:11.931 | raise ReadTimeoutError(self._pool, None, &apos;Read timed out.&apos;)2017-03-21 07:54:11.931 | ReadTimeoutError: HTTPSConnectionPool(host=&apos;pypi.python.org&apos;, port=443): Read timed out.报错解决:./stack.sh: line 488: generate-subunit: command not foundsudo apt-get install python-pip -ysudo pip install --upgrade pipsudo pip install -U os-testr报错:File &quot;/usr/local/lib/python2.7/dist-packages/openstack/session.py&quot;, line 29, in &lt;module&gt;2017-03-20 04:52:02.612 | DEFAULT_USER_AGENT = &quot;openstacksdk/%s&quot; % openstack.__version__2017-03-20 04:52:02.612 | AttributeError: &apos;module&apos; object has no attribute &apos;__version__&apos;2017-03-20 04:52:02.643 | +lib/keystone:create_keystone_accounts:373 admin_tenant=处理:root@ubuntu:~# python &gt;&gt;&gt; import openstack &gt;&gt;&gt; import pbr.version &gt;&gt;&gt; print(pbr.version.VersionInfo(&apos;openstacksdk&apos;).version_string()) 8 0.8.1 &gt;&gt;&gt; quit() vim /usr/local/lib/python2.7/dist-packages/openstack/session.py修改为： DEFAULT_USER_AGENT = &quot;openstacksdk/0.8.1&quot;./stack.sh 在ubuntu上搭建sambasudo apt-get install samba samba-common -y 我们把devstack安装在了/opt目录下，所以共享这个目录#sudo chmod -R 777 /optsudo useradd openstacksudo smbpasswd -a openstacksudo vim /etc/samba/smb.conf在文件末尾添加：[openstack]comment=openstackpublic=yesbrowseable = yespath=/optread only = no forceuser=rootforcegroup=root #################################################### 重启服务sudo /etc/init.d/smbd restart ```","tags":[{"name":"Openstack","slug":"Openstack","permalink":"http://yoursite.com/tags/Openstack/"}]},{"title":"python代码调试工具","date":"2017-03-29T15:37:00.000Z","path":"2017/03/29/python 调试工具/","text":"以前都是用print或者log来调试程序,在小规模的程序下很方便，但是遇到向openstack这种项目级别的程序就太尴尬了。于是找到了ipdb 1、安装 1pip install ipdb 2、使用方法有两种使用方法,一种是不用改变程序直接用ipdb单步执行Python程序,第二种是在程序里标记断点,进行调试. 1) 第一种方法 1python -m ipdb xxx.py 2) 第二种方法 在需要断点的地方插入 12from ipdb import set_traceset_trace() 3、常用命令 n(下一个) ENTER(重复上次命令) q(退出) p&lt;变量&gt;(打印变量) c(继续) l(查找当前位于哪里) s(进入子程序) r(运行直到子程序结束) ! h(帮助) 如果上面的工具觉得好用的话，下面这款工具真心觉得用的爽。 1、安装1pip install pudb 2、在代码的入口处插入 1from pudb import set_trace; set_trace() 3、调试代码 1sudo pudb bp.py 4、简单使用 1Ctrl-p可以配置pudb: 是否显示行号, 选择主题, 内置Python解释器的类别 n: next，也就是执行一步 s: step into，进入函数内部 c: continue b: break point，断点 !: python command line ?: help","tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"ceilometer-mitaka api分析","date":"2017-03-29T14:36:22.000Z","path":"2017/03/29/ceilometer-mitaka api分析/","text":"本文的讲解是基于目前ceilometer的mitaka版本 ceilometer –debug meter-list的调用流程分析 大概过程 python-ceilometerclient ceilometer –debug meter-list curl GET http://192.168.12.10:8777/v2/meters Python Application的创建 HTTP请求的解析 RootController V2Controller MetersController 实际去获取数据的两个函数 pecan.request.storage_conn.get_meters的执行 Meter.from_db_model的执行 curl GET http://192.168.12.10:8777/v2/meters 这句很重要，下面我们就分析ceilometer收到这个HTTP请求后是如何解析，如何使用Python Application去查询MongoDB数据库的 1、Python Application的创建过程需要使用Python Application来接收HTTP请求，因此需要先创建Python Application。下面我们介绍使用Pecan+PasetDeploy创建Python Application的过程。 1在配置文件api_pasete.ini中我们可以看到，PasteDeploy会调用ceilometer.api.app:app_factory。 123456789101112131415[pipeline:main]pipeline = cors request_id authtoken api-server[app:api-server]paste.app_factory = ceilometer.api.app:app_factory[filter:authtoken]paste.filter_factory = keystonemiddleware.auth_token:filter_factory[filter:request_id]paste.filter_factory = oslo_middleware:RequestId.factory[filter:cors]paste.filter_factory = oslo_middleware.cors:filter_factoryoslo_config_project = ceilometer 根据[app:api-server] 我们得知app_factory函数的具体位置返回的是setup_app() 12def app_factory(global_config, **local_conf): return setup_app() setup_app函数就是真正创建Python Application的函数，在此函数中最重要的就是调用了pecan.make_app函数，在此函数中最重要的就是指定了解析HTTP Request的RootController，是通过pecan_config.app.root参数指定的；另外一个重要的地方就是hoooks.DBHook，在这里面初始化了数据库的链接，关于这一点后面再做介绍。 1234567891011121314151617181920212223242526272829303132def setup_app(pecan_config=None): # FIXME: Replace DBHook with a hooks.TransactionHook app_hooks = [hooks.ConfigHook(), hooks.DBHook(), hooks.NotifierHook(), hooks.TranslationHook()] pecan_config = pecan_config or &#123; &quot;app&quot;: &#123; &apos;root&apos;: &apos;ceilometer.api.controllers.root.RootController&apos;, &apos;modules&apos;: [&apos;ceilometer.api&apos;], &#125; &#125; pecan.configuration.set_config(dict(pecan_config), overwrite=True) # NOTE(sileht): pecan debug won&apos;t work in multi-process environment pecan_debug = CONF.api.pecan_debug if CONF.api.workers and CONF.api.workers != 1 and pecan_debug: pecan_debug = False LOG.warning(_LW(&apos;pecan_debug cannot be enabled, if workers is &gt; 1, &apos; &apos;the value is overrided with False&apos;)) app = pecan.make_app( pecan_config[&apos;app&apos;][&apos;root&apos;], debug=pecan_debug, hooks=app_hooks, wrap_app=middleware.ParsableErrorMiddleware, guess_content_type_from_ext=False ) return app 在上面我们提到解析HTTP请求的RootController是通过pecan_config.app.root参数指定的，阅读代码可知pecan_config.app.root就pecan_config中指定的，也就是ceilometer.api.controllers.root.RootController。这样Python Application就创建完成了，并且指定好了解析HTTP Request的RootController，也就是说/v2/meters/从RootController开始处理。 2、HTTP请求的解析过程在RootController我们可以看到它先创建了一个类属性:v2，于是所有的以/v2开头的HTTP Request都会由V2Controller来处理，/v2/meters/当然也不例外 12345678910111213class RootController(object): def __init__(self): self.v2 = v2.V2Controller() @pecan.expose(&apos;json&apos;) def index(self): base_url = pecan.request.application_url available = [&#123;&apos;tag&apos;: &apos;v2&apos;, &apos;date&apos;: &apos;2013-02-13T00:00:00Z&apos;, &#125;] collected = [version_descriptor(base_url, v[&apos;tag&apos;], v[&apos;date&apos;]) for v in available] versions = &#123;&apos;versions&apos;: &#123;&apos;values&apos;: collected&#125;&#125; return versions 下面我们再去看V2Controller，我们可以看到它有类属性:event_types,events,capabilities，也就是说/v2/event_types会由EventTypesController来处理，/v2/events/会由EventsController来处理，/v2/capabilities/会由CapabilitiesController来处理，那/v2/meters/呢？往下看，在_lookup函数中我们可以看到/v2/meters/会由MetersController来处理，关于__lookup可以参看官方文档。 123456class V2Controller(object): &quot;&quot;&quot;Version 2 API controller root.&quot;&quot;&quot; event_types = events.EventTypesController() events = events.EventsController() capabilities = capabilities.CapabilitiesController() 12345678910111213141516171819202122232425262728@pecan.expose() def _lookup(self, kind, *remainder): if (kind in [&apos;meters&apos;, &apos;resources&apos;, &apos;samples&apos;] and self.gnocchi_is_enabled): if kind == &apos;meters&apos; and pecan.request.method == &apos;POST&apos;: direct = pecan.request.params.get(&apos;direct&apos;, &apos;&apos;) if strutils.bool_from_string(direct): pecan.abort(400, _(&apos;direct option cannot be true when &apos; &apos;Gnocchi is enabled.&apos;)) return meters.MetersController(), remainder gnocchi_abort() elif kind == &apos;meters&apos;: return meters.MetersController(), remainder elif kind == &apos;resources&apos;: return resources.ResourcesController(), remainder elif kind == &apos;samples&apos;: return samples.SamplesController(), remainder elif kind == &apos;query&apos;: return QueryController( gnocchi_is_enabled=self.gnocchi_is_enabled, aodh_url=self.aodh_url, ), remainder elif kind == &apos;alarms&apos; and (not self.aodh_url): aodh_abort() elif kind == &apos;alarms&apos; and self.aodh_url: aodh_redirect(self.aodh_url) else: pecan.abort(404) 因为我们是meters所以最终会执行1return meters.MetersController(), remainder 终于到了MetersController，这里就是最终处理HTTP请求:/v2/meters/的地方 12345678910111213141516171819202122232425262728class MetersController(rest.RestController): &quot;&quot;&quot;Works on meters.&quot;&quot;&quot; @pecan.expose() def _lookup(self, meter_name, *remainder): return MeterController(meter_name), remainder @wsme_pecan.wsexpose([Meter], [base.Query], int, str) def get_all(self, q=None, limit=None, unique=&apos;&apos;): &quot;&quot;&quot;Return all known meters, based on the data recorded so far. :param q: Filter rules for the meters to be returned. :param unique: flag to indicate unique meters to be returned. &quot;&quot;&quot; rbac.enforce(&apos;get_meters&apos;, pecan.request) q = q or [] # Timestamp field is not supported for Meter queries limit = v2_utils.enforce_limit(limit) kwargs = v2_utils.query_to_kwargs( q, pecan.request.storage_conn.get_meters, [&apos;limit&apos;], allow_timestamps=False) return [Meter.from_db_model(m) for m in pecan.request.storage_conn.get_meters( limit=limit, unique=strutils.bool_from_string(unique), **kwargs)] 在这里最重要的就是最后那一行代码：return [Meter.from_db_model(m) for m in pecan.request.storage_conn.get_meters(limit=limit,**kwargs)]，在这行代码中有两个重要的函数调用：pecan.request.storage_conn.get_meters 以及 Meter.from_db_model。所以还没结束，下面还得分析这两个函数是如何执行的。 pecan.request.storage_conn.get_meters的执行过程要分析pecan.request.storage_conn.get_meters(limit=limit, **kwargs)的执行过程我们分两步：一是storage_conn是如何获得的，二是get_meters是如何执行的。 storage_conn指的是数据库的链接，在DBHook.init中可以看出它是通过调用函数get_connection来获得的，而函数get_connection又调用了函数storage.get_connection_from_config。 123456789101112131415161718192021222324class DBHook(hooks.PecanHook): def __init__(self): self.storage_connection = DBHook.get_connection(&apos;metering&apos;) self.event_storage_connection = DBHook.get_connection(&apos;event&apos;) if (not self.storage_connection and not self.event_storage_connection): raise Exception(&quot;Api failed to start. Failed to connect to &quot; &quot;databases, purpose: %s&quot; % &apos;, &apos;.join([&apos;metering&apos;, &apos;event&apos;])) def before(self, state): state.request.storage_conn = self.storage_connection state.request.event_storage_conn = self.event_storage_connection @staticmethod def get_connection(purpose): try: return storage.get_connection_from_config(cfg.CONF, purpose) except Exception as err: params = &#123;&quot;purpose&quot;: purpose, &quot;err&quot;: err&#125; LOG.exception(_LE(&quot;Failed to connect to db, purpose %(purpose)s &quot; &quot;retry later: %(err)s&quot;) % params) 下面再看storage.get_connection_from_config函数是如何执行的，函数storage.get_connection_from_config调用了函数storage.get_connection，而在函数storage.get_connection中重要的是: mgr = driver.DriverManger(namespace, engine_name)，其中的driver为：from stevedore import driver，namespace为：ceilometer.meterings.storage，engine_name为：mongodb。于是stevedore会到setup.cfg中查找相应的设置。 12345678910111213141516171819202122232425262728293031323334def get_connection_from_config(conf, purpose=&apos;metering&apos;): retries = conf.database.max_retries # Convert retry_interval secs to msecs for retry decorator @retrying.retry(wait_fixed=conf.database.retry_interval * 1000, stop_max_attempt_number=retries if retries &gt;= 0 else None) def _inner(): if conf.database_connection: conf.set_override(&apos;connection&apos;, conf.database_connection, group=&apos;database&apos;) namespace = &apos;ceilometer.%s.storage&apos; % purpose url = (getattr(conf.database, &apos;%s_connection&apos; % purpose) or conf.database.connection) return get_connection(url, namespace) return _inner()def get_connection(url, namespace): &quot;&quot;&quot;Return an open connection to the database.&quot;&quot;&quot; connection_scheme = urlparse.urlparse(url).scheme # SqlAlchemy connections specify may specify a &apos;dialect&apos; or # &apos;dialect+driver&apos;. Handle the case where driver is specified. engine_name = connection_scheme.split(&apos;+&apos;)[0] if engine_name == &apos;db2&apos;: import warnings warnings.simplefilter(&quot;always&quot;) import debtcollector debtcollector.deprecate(&quot;The DB2nosql driver is no longer supported&quot;, version=&quot;Liberty&quot;, removal_version=&quot;N*-cycle&quot;) # NOTE: translation not applied bug #1446983 LOG.debug(&apos;looking for %(name)r driver in %(namespace)r&apos;, &#123;&apos;name&apos;: engine_name, &apos;namespace&apos;: namespace&#125;) mgr = driver.DriverManager(namespace, engine_name) return mgr.driver(url) 根据 12from stevedore import driver namespace为：ceilometer.meterings.storage，engine_name为：mongodb 所以会去调用setup.cfg中的 12ceilometer.event.storage = mongodb = ceilometer.event.storage.impl_mongodb:Connection 在ceilometer.storage.imple_mongodb.Connection类的初始化函数中会初始化数据库的连接，没有相应collection的情况下新建相应collection，设置ttl等。 ../ceilometer/storage/impl_mongodb.py: Connection.init123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112class Connection(pymongo_base.Connection): CAPABILITIES = utils.update_nested(pymongo_base.Connection.CAPABILITIES, AVAILABLE_CAPABILITIES) CONNECTION_POOL = pymongo_utils.ConnectionPool() STANDARD_AGGREGATES = dict([(a.name, a) for a in [ pymongo_utils.SUM_AGGREGATION, pymongo_utils.AVG_AGGREGATION, pymongo_utils.MIN_AGGREGATION, pymongo_utils.MAX_AGGREGATION, pymongo_utils.COUNT_AGGREGATION, ]]) AGGREGATES = dict([(a.name, a) for a in [ pymongo_utils.SUM_AGGREGATION, pymongo_utils.AVG_AGGREGATION, pymongo_utils.MIN_AGGREGATION, pymongo_utils.MAX_AGGREGATION, pymongo_utils.COUNT_AGGREGATION, pymongo_utils.STDDEV_AGGREGATION, pymongo_utils.CARDINALITY_AGGREGATION, ]]) SORT_OPERATION_MAPPING = &#123;&apos;desc&apos;: (pymongo.DESCENDING, &apos;$lt&apos;), &apos;asc&apos;: (pymongo.ASCENDING, &apos;$gt&apos;)&#125; MAP_RESOURCES = bson.code.Code(&quot;&quot;&quot; function () &#123; emit(this.resource_id, &#123;user_id: this.user_id, project_id: this.project_id, source: this.source, first_timestamp: this.timestamp, last_timestamp: this.timestamp, metadata: this.resource_metadata&#125;) &#125;&quot;&quot;&quot;) REDUCE_RESOURCES = bson.code.Code(&quot;&quot;&quot; function (key, values) &#123; var merge = &#123;user_id: values[0].user_id, project_id: values[0].project_id, source: values[0].source, first_timestamp: values[0].first_timestamp, last_timestamp: values[0].last_timestamp, metadata: values[0].metadata&#125; values.forEach(function(value) &#123; if (merge.first_timestamp - value.first_timestamp &gt; 0) &#123; merge.first_timestamp = value.first_timestamp; merge.user_id = value.user_id; merge.project_id = value.project_id; merge.source = value.source; &#125; else if (merge.last_timestamp - value.last_timestamp &lt;= 0) &#123; merge.last_timestamp = value.last_timestamp; merge.metadata = value.metadata; &#125; &#125;); return merge; &#125;&quot;&quot;&quot;) _GENESIS = datetime.datetime(year=datetime.MINYEAR, month=1, day=1) _APOCALYPSE = datetime.datetime(year=datetime.MAXYEAR, month=12, day=31, hour=23, minute=59, second=59) def __init__(self, url): # NOTE(jd) Use our own connection pooling on top of the Pymongo one. # We need that otherwise we overflow the MongoDB instance with new # connection since we instantiate a Pymongo client each time someone # requires a new storage connection. self.conn = self.CONNECTION_POOL.connect(url) self.version = self.conn.server_info()[&apos;versionArray&apos;] # Require MongoDB 2.4 to use $setOnInsert if self.version &lt; pymongo_utils.MINIMUM_COMPATIBLE_MONGODB_VERSION: raise storage.StorageBadVersion( &quot;Need at least MongoDB %s&quot; % pymongo_utils.MINIMUM_COMPATIBLE_MONGODB_VERSION) connection_options = pymongo.uri_parser.parse_uri(url) self.db = getattr(self.conn, connection_options[&apos;database&apos;]) if connection_options.get(&apos;username&apos;): self.db.authenticate(connection_options[&apos;username&apos;], connection_options[&apos;password&apos;]) # NOTE(jd) Upgrading is just about creating index, so let&apos;s do this # on connection to be sure at least the TTL is correctly updated if # needed. self.upgrade() @staticmethod def update_ttl(ttl, ttl_index_name, index_field, coll): &quot;&quot;&quot;Update or create time_to_live indexes. :param ttl: time to live in seconds. :param ttl_index_name: name of the index we want to update or create. :param index_field: field with the index that we need to update. :param coll: collection which indexes need to be updated. &quot;&quot;&quot; indexes = coll.index_information() if ttl &lt;= 0: if ttl_index_name in indexes: coll.drop_index(ttl_index_name) return if ttl_index_name in indexes: return coll.database.command( &apos;collMod&apos;, coll.name, index=&#123;&apos;keyPattern&apos;: &#123;index_field: pymongo.ASCENDING&#125;, &apos;expireAfterSeconds&apos;: ttl&#125;) coll.create_index([(index_field, pymongo.ASCENDING)], expireAfterSeconds=ttl, name=ttl_index_name)... get_meters的执行过程这里有一个类的继承关系：object &lt;– storage.base.Connection &lt;– storage.pymongo_base.Connection &lt;– storage.impl_mongodb.Connection，关于storage.impl_mongodb.Connection需要讲的都在上面提到了。 在storage.base.Connection中给出了一些函数定义，但都没有具体的实现。 在storage.pymongo_base.Connection中给出了get_meters的定义，在这里我们就可以真正的看到查询数据库的语句了: self.db.resource.find(q)，下面我们还要解释一下语句models.Meter。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class Connection(base.Connection): &quot;&quot;&quot;Base Connection class for MongoDB and DB2 drivers.&quot;&quot;&quot; CAPABILITIES = utils.update_nested(base.Connection.CAPABILITIES, COMMON_AVAILABLE_CAPABILITIES) STORAGE_CAPABILITIES = utils.update_nested( base.Connection.STORAGE_CAPABILITIES, AVAILABLE_STORAGE_CAPABILITIES, ) def get_meters(self, user=None, project=None, resource=None, source=None, metaquery=None, limit=None, unique=False): &quot;&quot;&quot;Return an iterable of models.Meter instances :param user: Optional ID for user that owns the resource. :param project: Optional ID for project that owns the resource. :param resource: Optional resource filter. :param source: Optional source filter. :param metaquery: Optional dict with metadata to match on. :param limit: Maximum number of results to return. :param unique: If set to true, return only unique meter information. &quot;&quot;&quot; if limit == 0: return metaquery = pymongo_utils.improve_keys(metaquery, metaquery=True) or &#123;&#125; q = &#123;&#125; if user == &apos;None&apos;: q[&apos;user_id&apos;] = None elif user is not None: q[&apos;user_id&apos;] = user if project == &apos;None&apos;: q[&apos;project_id&apos;] = None elif project is not None: q[&apos;project_id&apos;] = project if resource == &apos;None&apos;: q[&apos;_id&apos;] = None elif resource is not None: q[&apos;_id&apos;] = resource if source is not None: q[&apos;source&apos;] = source q.update(metaquery) count = 0 if unique: meter_names = set() for r in self.db.resource.find(q): for r_meter in r[&apos;meter&apos;]: if unique: if r_meter[&apos;counter_name&apos;] in meter_names: continue else: meter_names.add(r_meter[&apos;counter_name&apos;]) if limit and count &gt;= limit: return else: count += 1 if unique: yield models.Meter( name=r_meter[&apos;counter_name&apos;], type=r_meter[&apos;counter_type&apos;], # Return empty string if &apos;counter_unit&apos; is not valid # for backward compatibility. unit=r_meter.get(&apos;counter_unit&apos;, &apos;&apos;), resource_id=None, project_id=None, source=None, user_id=None) else: yield models.Meter( name=r_meter[&apos;counter_name&apos;], type=r_meter[&apos;counter_type&apos;], # Return empty string if &apos;counter_unit&apos; is not valid # for backward compatibility. unit=r_meter.get(&apos;counter_unit&apos;, &apos;&apos;), resource_id=r[&apos;_id&apos;], project_id=r[&apos;project_id&apos;], source=r[&apos;source&apos;], user_id=r[&apos;user_id&apos;]) 这里又有一个类的继承关系：object &lt;– storage.base.Model &lt;– storage.models.Meter。 这里其实就是把查询到的值和键做个对应的设置。 1234567891011121314151617181920212223242526class Model(object): &quot;&quot;&quot;Base class for storage API models.&quot;&quot;&quot; def __init__(self, **kwds): self.fields = list(kwds) for k, v in six.iteritems(kwds): setattr(self, k, v) def as_dict(self): d = &#123;&#125; for f in self.fields: v = getattr(self, f) if isinstance(v, Model): v = v.as_dict() elif isinstance(v, list) and v and isinstance(v[0], Model): v = [sub.as_dict() for sub in v] d[f] = v return d def __eq__(self, other): return self.as_dict() == other.as_dict() @classmethod def get_field_names(cls): fields = inspect.getargspec(cls.__init__)[0] return set(fields) - set([&quot;self&quot;]) Meter.from_db_model(m)的执行过程这里有个类的继承关系：wsme.types.Base &lt;– wsme.types.DynamicBase &lt;– api.controllers.v2.base.Base &lt;– api.v2.meters.Meter 后面api.v2.meters.Meter的初始化函数调用了wsme.types.Base.init函数。 123456789101112131415161718192021222324252627282930class Base(six.with_metaclass(BaseMeta)): &quot;&quot;&quot;Base type for complex types&quot;&quot;&quot; def __init__(self, **kw): for key, value in kw.items(): if hasattr(self, key): setattr(self, key, value) class DynamicBase(Base): &quot;&quot;&quot;Base type for complex types for which all attributes are not defined when the class is constructed. This class is meant to be used as a base for types that have properties added after the main class is created, such as by loading plugins. &quot;&quot;&quot; @classmethod def add_attributes(cls, **attrs): &quot;&quot;&quot;Add more attributes The arguments should be valid Python attribute names associated with a type for the new attribute. &quot;&quot;&quot; for n, t in attrs.items(): setattr(cls, n, t) cls.__registry__.reregister(cls) 函数Meter.from_db_model定义在ceilometer.api.controllers.v2.base:Base中，函数Meter.from_db_model是把返回的ceilometer.storage.models.Meter实例， 进一步做一些简单的处理。 123456789101112131415161718192021class Base(wtypes.DynamicBase): @classmethod def from_db_model(cls, m): return cls(**(m.as_dict())) @classmethod def from_db_and_links(cls, m, links): return cls(links=links, **(m.as_dict())) def as_dict(self, db_model): valid_keys = inspect.getargspec(db_model.__init__)[0] if &apos;self&apos; in valid_keys: valid_keys.remove(&apos;self&apos;) return self.as_dict_from_keys(valid_keys) def as_dict_from_keys(self, keys): return dict((k, getattr(self, k)) for k in keys if hasattr(self, k) and getattr(self, k) != wsme.Unset) Meter是在ceilometer.api.v2.meters中定义的，Meter中定义它的的类属性:name, type, unit, resource_id, project_id, user_id, source, meter_id；Meter中还定义了初始化函数init，该初始化函数主要是构造meter_id和调用wsme.types.Base的初始化函数init。 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Meter(base.Base): &quot;&quot;&quot;One category of measurements.&quot;&quot;&quot; name = wtypes.text &quot;The unique name for the meter&quot; type = wtypes.Enum(str, *sample.TYPES) &quot;The meter type (see :ref:`measurements`)&quot; unit = wtypes.text &quot;The unit of measure&quot; resource_id = wtypes.text &quot;The ID of the :class:`Resource` for which the measurements are taken&quot; project_id = wtypes.text &quot;The ID of the project or tenant that owns the resource&quot; user_id = wtypes.text &quot;The ID of the user who last triggered an update to the resource&quot; source = wtypes.text &quot;The ID of the source that identifies where the meter comes from&quot; meter_id = wtypes.text &quot;The unique identifier for the meter&quot; def __init__(self, **kwargs): meter_id = &apos;%s+%s&apos; % (kwargs[&apos;resource_id&apos;], kwargs[&apos;name&apos;]) # meter_id is of type Unicode but base64.encodestring() only accepts # strings. See bug #1333177 meter_id = base64.b64encode(meter_id.encode(&apos;utf-8&apos;)) kwargs[&apos;meter_id&apos;] = meter_id super(Meter, self).__init__(**kwargs) @classmethod def sample(cls): return cls(name=&apos;instance&apos;, type=&apos;gauge&apos;, unit=&apos;instance&apos;, resource_id=&apos;bd9431c1-8d69-4ad3-803a-8d4a6b89fd36&apos;, project_id=&apos;35b17138-b364-4e6a-a131-8f3099c5be68&apos;, user_id=&apos;efd87807-12d2-4b38-9c70-5f5c2ac427ff&apos;, source=&apos;openstack&apos;, ) 完毕。本文只是简单梳理了一些的代码流程，没有对于细节问题深究。","tags":[{"name":"Openstack","slug":"Openstack","permalink":"http://yoursite.com/tags/Openstack/"}]}]